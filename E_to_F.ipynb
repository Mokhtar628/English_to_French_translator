{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaVZRKcM24By",
        "outputId": "697d5005-d112-41fd-baa5-266cf0c43ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNLDMA-E28Cl"
      },
      "outputs": [],
      "source": [
        "with open(\"C:\\\\Users\\\\Hossam\\\\Desktop\\\\NLP_projectDataset\\\\en.txt\") as file:\n",
        "    en_data = [\"sos \"+line.rstrip()+\" eos\" for line in file]\n",
        "\n",
        "with open(\"C:\\\\Users\\\\Hossam\\\\Desktop\\\\NLP_projectDataset\\\\fr.txt\") as file:\n",
        "    fr_data = [\"sos \" + line.rstrip() +\" eos\" for line in file]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKMAcd1328FE",
        "outputId": "bc2f5946-1a30-46ad-d68a-c9687b7ef7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the original:  sos new jersey is sometimes quiet during autumn , and it is snowy in april . eos\n",
            "the translation:  sos new jersey est parfois calme pendant l' automne , et il est neigeux en avril . eos\n",
            "the original:  sos the united states is usually chilly during july , and it is usually freezing in november . eos\n",
            "the translation:  sos les états-unis est généralement froid en juillet , et il gèle habituellement en novembre . eos\n"
          ]
        }
      ],
      "source": [
        "for en_sent, fr_sent in zip(en_data[:2], fr_data[:2]):\n",
        "  print(\"the original: \", en_sent)\n",
        "  print(\"the translation: \", fr_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMu0GYem28Hd",
        "outputId": "d202ca69-4090-45d8-9269-eeb5ec99fc3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(English) Mean sentence length:  15.225678224285508\n",
            "(English) Vocabulary size:  230\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "en_sent_lengths = [len(en_sent.split(\" \")) for en_sent in en_data]\n",
        "en_mean_length = np.mean(en_sent_lengths)\n",
        "print('(English) Mean sentence length: ', en_mean_length)\n",
        "\n",
        "\n",
        "all_words = []\n",
        "for sent in en_data:\n",
        "  all_words.extend(sent.split(\" \"))\n",
        "en_vocab_size = len(set(all_words))\n",
        "print(\"(English) Vocabulary size: \", en_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yAbtXBY-28ME"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, GRU\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "en_inputs = Input(shape=(15, en_vocab_size))\n",
        "\n",
        "en_gru = GRU(256, return_state=True)\n",
        "en_out, en_state = en_gru(en_inputs)\n",
        "\n",
        "encoder = Model(inputs=en_inputs, outputs=en_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GvkMqQL28OQ",
        "outputId": "e54d2add-749a-4aa1-960d-3127b306d312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(French) Mean sentence length:  16.226730015958218\n",
            "(French) Vocabulary size:  358\n"
          ]
        }
      ],
      "source": [
        "sent_lengths = [len(fr_sent.split(\" \")) for fr_sent in fr_data]\n",
        "fr_mean_length = np.mean(sent_lengths)\n",
        "print('(French) Mean sentence length: ', fr_mean_length)\n",
        "\n",
        "all_words = []\n",
        "for sent in fr_data:\n",
        "  all_words.extend(sent.split(\" \"))\n",
        "fr_vocab_size = len(set(all_words))\n",
        "print(\"(French) Vocabulary size: \", fr_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-CV1owXR28Qe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import RepeatVector\n",
        "\n",
        "de_inputs = RepeatVector(15)(en_state)\n",
        "\n",
        "decoder_gru = GRU(256, return_sequences=True)\n",
        "\n",
        "gru_outputs = decoder_gru(de_inputs, initial_state=en_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdCGM-f44Ba8",
        "outputId": "a9f3ace9-1996-45f5-97bd-5eb8d737bbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 15, 230)]    0           []                               \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, 256),        374784      ['input_1[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 15, 256)      0           ['gru[0][1]']                    \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 15, 256)      394752      ['repeat_vector[0][0]',          \n",
            "                                                                  'gru[0][1]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 769,536\n",
            "Trainable params: 769,536\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "enc_dec = Model(inputs=en_inputs, outputs=gru_outputs) # the sequenece to seq model\n",
        "print(enc_dec.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "98tmt5Tw4BdS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, TimeDistributed\n",
        "\n",
        "de_dense = Dense(fr_vocab_size, activation='softmax')\n",
        "de_dense_time = TimeDistributed(de_dense)\n",
        "de_pred = de_dense_time(gru_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S442WvRj28S2"
      },
      "outputs": [],
      "source": [
        "nmt = Model(inputs=en_inputs, outputs=de_pred)\n",
        "nmt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dfpgOS-l4KRj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Define a Keras Tokenizer\n",
        "en_tok = Tokenizer(num_words=230, oov_token='UNK')\n",
        "en_tok.fit_on_texts(en_data)\n",
        "fr_tok= Tokenizer(num_words=358, oov_token='UNK')\n",
        "fr_tok.fit_on_texts(fr_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V44hExhC4Kaq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def en_sents2seqs(input_type, sentences, onehot=False, pad_type='post', reverse=False):\n",
        "    encoded_text = en_tok.texts_to_sequences(sentences)\n",
        "    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=15)\n",
        "    if reverse:\n",
        "      # Reverse the text using numpy axis reversing\n",
        "      preproc_text = preproc_text[:,::-1]\n",
        "    if onehot:\n",
        "        preproc_text = to_categorical(preproc_text, num_classes=en_vocab_size)\n",
        "    return preproc_text\n",
        "\n",
        "def fr_sents2seqs(input_type, sentences, onehot=False, pad_type='post', reverse=False):\n",
        "    encoded_text = fr_tok.texts_to_sequences(sentences)\n",
        "    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=15)\n",
        "    if reverse:\n",
        "      # Reverse the text using numpy axis reversing\n",
        "      preproc_text = preproc_text[:,::-1]\n",
        "    if onehot:\n",
        "        preproc_text = to_categorical(preproc_text, num_classes=fr_vocab_size)\n",
        "    return preproc_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2SxTixC4Khj",
        "outputId": "079ea994-fc39-4ad6-9436-a902ad21908f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110288\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "train_size, valid_size = math.floor(len(en_data)*0.8), math.floor(len(en_data)*0.2)\n",
        "inds = np.arange(len(en_data))\n",
        "np.random.shuffle(inds)\n",
        "train_inds = inds[:train_size]\n",
        "valid_inds = inds[train_size:train_size+valid_size]\n",
        "\n",
        "tr_en = [en_data[ti] for ti in train_inds]\n",
        "tr_fr = [fr_data[ti] for ti in train_inds]\n",
        "v_en = [en_data[ti] for ti in valid_inds]\n",
        "v_fr = [fr_data[ti] for ti in valid_inds]\n",
        "\n",
        "print(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Zsa53U4e8s",
        "outputId": "addc9386-1c8e-4149-d93d-d88341ae2dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 => Loss:1.032729148864746, Val Acc: 67.95807480812073\n",
            "Epoch: 2 => Loss:0.45387357473373413, Val Acc: 86.79215908050537\n",
            "Epoch: 3 => Loss:0.25966891646385193, Val Acc: 92.14227199554443\n",
            "Epoch: 4 => Loss:0.19778800010681152, Val Acc: 93.98738145828247\n",
            "Epoch: 5 => Loss:0.16945427656173706, Val Acc: 94.82614994049072\n",
            "Epoch: 6 => Loss:0.14245742559432983, Val Acc: 95.6487238407135\n",
            "Epoch: 7 => Loss:0.1310824155807495, Val Acc: 95.96281051635742\n",
            "Epoch: 8 => Loss:0.13977506756782532, Val Acc: 95.84336876869202\n",
            "Epoch: 9 => Loss:0.12922358512878418, Val Acc: 96.13303542137146\n",
            "Epoch: 10 => Loss:0.12405239790678024, Val Acc: 96.40021324157715\n",
            "Epoch: 11 => Loss:0.11237531900405884, Val Acc: 96.71212434768677\n",
            "Epoch: 12 => Loss:0.10506541281938553, Val Acc: 96.93142771720886\n",
            "Epoch: 13 => Loss:0.11304385960102081, Val Acc: 96.84631824493408\n",
            "Epoch: 14 => Loss:0.12102416902780533, Val Acc: 96.71913385391235\n",
            "Epoch: 15 => Loss:0.10307396948337555, Val Acc: 97.04385995864868\n",
            "Epoch: 16 => Loss:0.11525735259056091, Val Acc: 96.80593609809875\n",
            "Epoch: 17 => Loss:0.09652724862098694, Val Acc: 97.36616611480713\n",
            "Epoch: 18 => Loss:0.0946417823433876, Val Acc: 97.42009043693542\n",
            "Epoch: 19 => Loss:0.13484074175357819, Val Acc: 96.82721495628357\n",
            "Epoch: 20 => Loss:0.09822383522987366, Val Acc: 97.4034070968628\n",
            "Epoch: 21 => Loss:0.1183917298913002, Val Acc: 97.04168438911438\n",
            "Epoch: 22 => Loss:0.09984693676233292, Val Acc: 97.48634099960327\n",
            "Epoch: 23 => Loss:0.12309917062520981, Val Acc: 97.03370332717896\n",
            "Epoch: 24 => Loss:0.09469403326511383, Val Acc: 97.56879210472107\n",
            "Epoch: 25 => Loss:0.11699725687503815, Val Acc: 97.16983437538147\n",
            "Epoch: 26 => Loss:0.11570708453655243, Val Acc: 97.08690047264099\n",
            "Epoch: 27 => Loss:0.1180763691663742, Val Acc: 97.28661775588989\n",
            "Epoch: 28 => Loss:0.11753308027982712, Val Acc: 97.28831052780151\n",
            "Epoch: 29 => Loss:0.1013982743024826, Val Acc: 97.59151935577393\n",
            "Epoch: 30 => Loss:0.10470672696828842, Val Acc: 97.4319338798523\n"
          ]
        }
      ],
      "source": [
        "v_en_x = en_sents2seqs('source', v_en, onehot=True, pad_type='pre')\n",
        "v_de_y = fr_sents2seqs('target', v_fr, onehot=True)\n",
        "n_epochs, bsize = 30, 32\n",
        "for ei in range(n_epochs):\n",
        "  for i in range(0,train_size,bsize):\n",
        "    en_x = en_sents2seqs('source', tr_en[i:i+bsize], onehot=True, pad_type='pre')\n",
        "    de_y = fr_sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n",
        "    nmt.train_on_batch(en_x, de_y)\n",
        "\n",
        "  res = nmt.evaluate(v_en_x, v_de_y, batch_size=valid_size, verbose=0)\n",
        "  print(\"Epoch: {} => Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_QxSqqqM4nZE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]]]\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "[ 3 36  2 68 18 28 82 59  9  6  2 15 22 29 14]\n",
            " sos france est occupé au mois d' août et il est généralement froid à l'\n"
          ]
        }
      ],
      "source": [
        "# new jersey is sometimes quiet during autumn\n",
        "en_sent = [\"sos france is busy during august eos\"]\n",
        "en_seq = en_sents2seqs('source', en_sent, onehot=True, reverse=False)\n",
        "print(en_seq)\n",
        "\n",
        "fr_pred = nmt.predict(en_seq)\n",
        "fr_seq = np.argmax(fr_pred, axis=-1)[0]\n",
        "\n",
        "print(fr_seq)\n",
        "translation = ''\n",
        "for i in fr_seq:\n",
        "  if i == 0:break\n",
        "  translation += ' ' + fr_tok.index_word[i]\n",
        "\n",
        "print(translation)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
